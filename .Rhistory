mu = 0
b = 1
xs = seq(-10, 10, length.out = 100)
ys = 1 / (2 * b) * exp(- abs(xs - mu) / b)
plot(xs, ys)
ys = 1 / (2 * b) * exp(- abs(xs - mu) / b)
data.frame(xs, ys) %>% ggplot(aes(xs, ys)) +
geom_point()
data.frame(xs, ys) %>% ggplot(aes(xs, ys)) +
geom_line() + xlab("X") + ylab("PDF") + myTheme
data = read.table("laplace_samples.dat")[[1]]
str(data)
length(data)
data
length(data)
data = read.table("laplace_samples.dat")
meanHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
data = read.table("laplace_samples.dat")
meanHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
mean((medianHats - mu) ^ 2)
(medianHats - mu)
apply(data, MARGIN = 1, median)
edianHats
str(medianHats)
meanHats = as.numeric(apply(data, MARGIN = 1, mean))
data = read.table("laplace_samples.dat")
data = as.numeric(data)
data = sapply(1 :5, function(i), as.numeric(data[[i]]))
data = sapply(1 :5, function(i) as.numeric(data[[i]]))
meanHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
data = read.table("laplace_samples.dat")
data = sapply(1 :5, function(i) as.numeric(data[[i]]))
meanHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
muBias
muMSE
medianBias
medianMES
apply(data, MARGIN = 1, median)
View(data)
data = read.table("laplace_samples.dat", header = T)
data = sapply(1 :5, function(i) as.numeric(data[[i]]))
meanHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
mean((medianHats - mu) ^ 2)
mean(medianHats) - mu
mean((muHats - mu) ^ 2)
mean(muHats) - mu
mean((muHats - mu) ^ 2)
mean((medianHats - mu) ^ 2)
mean(muHats) - mu
mu
data = read.table("laplace_samples.dat", header = T)
data = sapply(1 :5, function(i) as.numeric(data[[i]]))
meanHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
mean(muHats) - mu
mean((muHats - mu) ^ 2)
mean(medianHats) - mu
data = read.table("laplace_samples.dat", header = T)
data = sapply(1 :5, function(i) as.numeric(data[[i]]))
muHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
mean(muHats) - mu
mean((muHats - mu) ^ 2)
data = read.table("laplace_samples.dat", header = T)
data = sapply(1 :5, function(i) as.numeric(data[[i]]))
muHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
mean(medianHats) - mu
mean((medianHats - mu) ^ 2)
data = read.table("laplace_samples.dat", header = T)
data = sapply(1 :5, function(i) as.numeric(data[[i]]))
muHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
data = read.table("laplace_samples.dat", header = T)
data = sapply(1 :5, function(i) as.numeric(data[[i]]))
muHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
library("ggplot2")
library("tidyr")
library("dplyr")
library("SuppDists")
source("subFxs/plotThemes.R")
rwd = 2
iti = 2
conditions = c("rich", "poor")
nCondition = length(conditions)
hts_ = list("rich" = c(16, 12, 8, 1.5, 1.5, 1.5, 1.5), "poor" = c(16, 16, 16, 16, 12, 8, 1.5))
unqHts = c(16, 12, 8, 1.5)
nUnqHt = length(unqHts)
chunkSize = 7
# calculate the optimal longRunRate
# accpet hts <= threshold
optimLongRunRate_ = list()
optimMaxAcpHt_ = list()
i = 1
blockSe
source('~/Documents/social_forage_new/optim.R', echo=TRUE)
blockSec
nSample = 1000
sampleSize = 5
mu = 0
set.seed(123)
muHats = replicate(nSample, mean(rnorm(sampleSize, mu, 1)))
medianHats = replicate(nSample, median(rnorm(sampleSize, mu, 1)))
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
mu = 0
b = 1
xs = seq(-10, 10, length.out = 100)
ys = 1 / (2 * b) * exp(- abs(xs - mu) / b)
data.frame(xs, ys) %>% ggplot(aes(xs, ys)) +
geom_line() + xlab("X") + ylab("PDF") + myTheme
library("ggplot2")
library("tidyr")
library("dplyr")
library("SuppDists")
source("subFxs/plotThemes.R")
library("ggplot2")
library("tidyr")
library("dplyr")
library("SuppDists")
source("subFxs/plotThemes.R")
mu = 0
b = 1
xs = seq(-10, 10, length.out = 100)
ys = 1 / (2 * b) * exp(- abs(xs - mu) / b)
data.frame(xs, ys) %>% ggplot(aes(xs, ys)) +
geom_line() + xlab("X") + ylab("PDF") + myTheme
data = read.table("laplace_samples.dat", header = T)
data = sapply(1 :5, function(i) as.numeric(data[[i]]))
muHats = apply(data, MARGIN = 1, mean)
medianHats = apply(data, MARGIN = 1, median)
muBias = mean(muHats) - mu
muMSE = mean((muHats - mu) ^ 2)
medianBias = mean(medianHats) - mu
medianMES = mean((medianHats - mu) ^ 2)
data = read.table("Retinal_ISIs.dat")[[1]]
n = length(data)
histResults = hist(data, breaks = seq(0.01, 191, length.out = 50))
mids = histResults$mids # middle x for each bar
breaks = histResults$breaks # breaks from the histogram
freqs = histResults$counts / n
# exponential model
mu = mean(data)
modelFreqs = diff(pexp(breaks, 1 / mu))
# plot hist
data.frame(mids, freqs, modelFreqs) %>%
ggplot(aes(mids, freqs)) + geom_bar(stat = "identity", color = "grey") +
geom_point(aes(mids, modelFreqs)) + geom_line(aes(mids, modelFreqs)) +
myTheme + xlab("x") + ylab("Relative Frequency")
# ks plot
data.frame(
empCDF = cumsum(c(0, freqs)),
theCDF = pexp(breaks, 1 / mu)
) %>% ggplot(aes(empCDF, theCDF)) + geom_point() + myTheme +
geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
xlab("Empirical CDF") + ylab("Fitted CDF")
# histrogram
histResults = hist(data, breaks = seq(0.01, 191, length.out = 50), plot = F)
mids = histResults$mids # middle x for each bar
breaks = histResults$breaks # breaks from the histogram
freqs = histResults$counts / n
# inverse Gaussian model
mu = mean(data)
lambda = n / sum(1 / data - 1 / mu)
modelFreqs = diff(pinvGauss(breaks, mu, lambda))
# plot hist
p = data.frame(mids, freqs, modelFreqs) %>%
ggplot(aes(mids, freqs)) + geom_bar(stat = "identity", color = "grey") +
geom_point(aes(mids, modelFreqs)) + geom_line(aes(mids, modelFreqs)) +
myTheme + xlab("x") + ylab("Relative Frequency")
print(p)
# ks plot
p = data.frame(
empCDF = cumsum(c(0, freqs)),
theCDF = pinvGauss(breaks, mu, lambda)
) %>% ggplot(aes(empCDF, theCDF)) + geom_point() + myTheme +
geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
xlab("Empirical CDF") + ylab("Fitted CDF")
print(p)
source('~/Documents/social_forage_new/learnCurve.R', echo=TRUE)
source('~/Documents/social_forage_new/social_nonSocial.R', echo=TRUE)
source('~/Documents/social_forage_new/learnCurve.R', echo=TRUE)
source("RL.R")
source("RLSocial.R")
library("ggplot2")
library("dplyr")
library("tidyr")
source("subFxs/plotThemes.R")
# output dir
dir.create("figures")
# simulation parameters
nSub = 32
# non_social
tGrid = c(seq(0, blockSec, by = 0.5), seq(0, blockSec, by = 0.5) + blockSec)
nT = length(tGrid)
acceptMatrix_ = array(NA, dim = c(nUnqHt,  nT, nSub))
for(sIdx in 1 : nSub){
beta = runif(1, 0.001, 0.01)
tau = runif(1, 10, 15)
iniLongRunRate = runif(1, 0.15, 1)
RLResults = RL(beta, tau, iniLongRunRate, htSeq_)
acceptMatrix_[, ,sIdx] = RLResults$acceptMatrixOnGrid
}
acceptMatrix = apply(acceptMatrix_, MARGIN = c(1,2), FUN = function(x) mean(x, rm.na = T))
plotData = data.frame(t(acceptMatrix)); colnames(plotData) =  paste(unqHts); plotData$time = tGrid
plotData$condition = rep(conditions, each = nT / 2)
nonSocialData = plotData
# social
tGrid = c(seq(0, blockSec, by = 0.5), seq(0, blockSec, by = 0.5) + blockSec)
nT = length(tGrid)
acceptMatrix_ = array(NA, dim = c(nUnqHt,  nT, nSub))
for(sIdx in 1 : nSub){
beta_self = runif(1, 0.001, 0.01)
beta_other = beta_self * 2
tau = runif(1, 10, 15)
iniLongRunRate = runif(1, 0.15, 1)
RLResults = RLSocial(beta_self, beta_other, tau, iniLongRunRate, htSeq_)
acceptMatrix_[, ,sIdx] = RLResults$acceptMatrixOnGrid
}
acceptMatrix = apply(acceptMatrix_, MARGIN = c(1,2), FUN = function(x) mean(x, rm.na = T))
plotData = data.frame(t(acceptMatrix)); colnames(plotData) =  paste(unqHts); plotData$time = tGrid
plotData$condition = rep(conditions, each = nT / 2)
socialData = plotData
# combine data from two conditions
aggData = rbind(gather(socialData, key = ht, value = pAccept, -time, -condition),
gather(nonSocialData, key = ht, value = pAccept, -time, -condition))
aggData$social = factor(rep(c("social", "non_social"), each = nT * nUnqHt),
levels = c("social", "non_social"))
# calculate the ideal behavior, assuming there is noise in actions
meanTau = 12.5
# aggData$optimPAccept = 1 / (1 + exp(meanTau * (as.numeric(aggData$ht) * as.numeric(optimLongRunRate_[aggData$condition]) - rwd)))
aggData$condition
optimMaxAcpHt_[[aggData$condition]]
optimMaxAcpHt_
optimMaxAcpHt_[aggData$condition]
as.numeric(optimMaxAcpHt_[aggData$condition])
source('~/Documents/social_forage_new/social_nonSocial.R', echo=TRUE)
source('~/Documents/social_forage_new/learnCurve.R', echo=TRUE)
as.numeric(aggData$ht)
unique(aggData$ht)
source('~/Documents/social_forage_new/optim.R', echo=TRUE)
source("RL.R")
source("RLSocial.R")
library("ggplot2")
library("dplyr")
library("tidyr")
source("subFxs/plotThemes.R")
# output dir
dir.create("figures")
# simulation parameters
nSub = 32
# non_social
tGrid = c(seq(0, blockSec, by = 0.5), seq(0, blockSec, by = 0.5) + blockSec)
nT = length(tGrid)
acceptMatrix_ = array(NA, dim = c(nUnqHt,  nT, nSub))
for(sIdx in 1 : nSub){
beta = runif(1, 0.001, 0.01)
tau = runif(1, 10, 15)
iniLongRunRate = runif(1, 0.15, 1)
RLResults = RL(beta, tau, iniLongRunRate, htSeq_)
acceptMatrix_[, ,sIdx] = RLResults$acceptMatrixOnGrid
}
acceptMatrix = apply(acceptMatrix_, MARGIN = c(1,2), FUN = function(x) mean(x, rm.na = T))
plotData = data.frame(t(acceptMatrix)); colnames(plotData) =  paste(unqHts); plotData$time = tGrid
plotData$condition = rep(conditions, each = nT / 2)
nonSocialData = plotData
# social
tGrid = c(seq(0, blockSec, by = 0.5), seq(0, blockSec, by = 0.5) + blockSec)
nT = length(tGrid)
acceptMatrix_ = array(NA, dim = c(nUnqHt,  nT, nSub))
for(sIdx in 1 : nSub){
beta_self = runif(1, 0.001, 0.01)
beta_other = beta_self * 2
tau = runif(1, 10, 15)
iniLongRunRate = runif(1, 0.15, 1)
RLResults = RLSocial(beta_self, beta_other, tau, iniLongRunRate, htSeq_)
acceptMatrix_[, ,sIdx] = RLResults$acceptMatrixOnGrid
}
acceptMatrix = apply(acceptMatrix_, MARGIN = c(1,2), FUN = function(x) mean(x, rm.na = T))
plotData = data.frame(t(acceptMatrix)); colnames(plotData) =  paste(unqHts); plotData$time = tGrid
plotData$condition = rep(conditions, each = nT / 2)
socialData = plotData
# combine data from two conditions
aggData = rbind(gather(socialData, key = ht, value = pAccept, -time, -condition),
gather(nonSocialData, key = ht, value = pAccept, -time, -condition))
aggData$social = factor(rep(c("social", "non_social"), each = nT * nUnqHt),
levels = c("social", "non_social"))
unique(aggData$ht)
# calculate the ideal behavior, assuming there is noise in actions
meanTau = 12.5
# aggData$optimPAccept = 1 / (1 + exp(meanTau * (as.numeric(aggData$ht) * as.numeric(optimLongRunRate_[aggData$condition]) - rwd)))
aggData$optimPAccept = ifelse(as.numeric(aggData$ht) <= as.numeric(optimMaxAcpHt_[aggData$condition]), 1, 0)
aggData %>% mutate(ht = factor(ht, levels = unqHts)) %>%
ggplot(aes(time, pAccept, color = social)) + geom_line(size = 1) +
scale_color_manual(values = c("red", "black")) + facet_wrap(~ht) +
geom_line(aes(time, optimPAccept), color = "#353535", linetype = "dashed") +
myTheme + xlab("Time (s)") + ylab("Percentage of accepted trials(%)") +
scale_y_continuous(limits = c(-0.1, 1.1), breaks = c(0, 0.5, 1))
tGrid = c(seq(0, blockSec, by = 0.5), seq(0, blockSec, by = 0.5) + blockSec)
nT = length(tGrid)
acceptMatrix_ = array(NA, dim = c(nUnqHt,  nT, nSub))
for(sIdx in 1 : nSub){
beta = runif(1, 0.001, 0.01)
tau = runif(1, 10, 15)
iniLongRunRate = runif(1, 0.15, 1)
RLResults = RL(beta, tau, iniLongRunRate, htSeq_)
acceptMatrix_[, ,sIdx] = RLResults$acceptMatrixOnGrid
}
acceptMatrix = apply(acceptMatrix_, MARGIN = c(1,2), FUN = function(x) mean(x, rm.na = T))
plotData = data.frame(t(acceptMatrix)); colnames(plotData) =  paste(unqHts); plotData$time = tGrid
plotData$condition = rep(conditions, each = nT / 2)
nonSocialData = plotData
unqHts
plotData$`11`
tGrid = c(seq(0, blockSec, by = 0.5), seq(0, blockSec, by = 0.5) + blockSec)
nT = length(tGrid)
acceptMatrix_ = array(NA, dim = c(nUnqHt,  nT, nSub))
for(sIdx in 1 : nSub){
beta_self = runif(1, 0.001, 0.01)
beta_other = beta_self * 2
tau = runif(1, 10, 15)
iniLongRunRate = runif(1, 0.15, 1)
RLResults = RLSocial(beta_self, beta_other, tau, iniLongRunRate, htSeq_)
acceptMatrix_[, ,sIdx] = RLResults$acceptMatrixOnGrid
}
acceptMatrix = apply(acceptMatrix_, MARGIN = c(1,2), FUN = function(x) mean(x, rm.na = T))
plotData = data.frame(t(acceptMatrix)); colnames(plotData) =  paste(unqHts); plotData$time = tGrid
plotData$condition = rep(conditions, each = nT / 2)
socialData = plotData
aggData = rbind(gather(socialData, key = ht, value = pAccept, -time, -condition),
gather(nonSocialData, key = ht, value = pAccept, -time, -condition))
aggData$social = factor(rep(c("social", "non_social"), each = nT * nUnqHt),
levels = c("social", "non_social"))
str(aggData)
unique(aggData$ht)
plot(aggData$pAccept)
plot(aggData$pAccept[as.numeric(aggData$ht) == 11])
as.numeric(aggData$ht)
plot(aggData$pAccept[as.numeric(aggData$ht) == 11])
sum(as.numeric(aggData$ht) == 11)
aggData$pAccept
table(aggData$pAccept)
plot(aggData$pAccept[as.numeric(aggData$ht) == 11])
aggData$pAccept[as.numeric(aggData$ht) == 11]
acceptMatrix_
acceptMatrix
RLResults$acceptMatrix
load("expParas.RData")
############################# model ################################
# initialize the estimate for the long-run reward rate
reRate = iniLongRunRate
# loop over conditions
for(c in 1 : nCondition){
condition = conditions[c]
htSeq = htSeq_[[c]]
# initialize recording variables
condition_ = rep(NA, length = nCondition * nTrialMax)
tIdxInChunk_ = rep(NA, length = nCondition * nTrialMax)
cIdxInBlock_ = rep(NA, length = nCondition * nTrialMax)
scheduledHt_ = rep(NA, length = nTrialMax * nCondition) # scheduled ht
spentHt_ = rep(NA, length = nTrialMax * nCondition) # variables to record spent time, if engage = ht otherwise = 0
blockTime_ = rep(NA, length = nTrialMax * nCondition)
trialEarnings_ = rep(NA, length = nTrialMax * nCondition) # variable to record trialEarnings
reRate_ = rep(NA, length = nTrialMax * nCondition) # variable to record reRate
delta_ = rep(NA, length = nTrialMax * nCondition) # diagnosis variable to record prediction errors
# loop over trials
blockTime = 0 # elapsedTime since the beginning of the block
tIdx = 1
while(blockTime < blockSec){
# current ht
scheduledHt = htSeq[[tIdx]]
# make the action
pAccept = 1 / (1 + exp( ((scheduledHt) * reRate - rwd) * tau))
action = ifelse(runif(1) <= pAccept, "accept", "forgo")
# record trialEarnings and spentHt
trialEarnings = ifelse(action == "accept", rwd, 0)
spentHt = ifelse(action == "accept", scheduledHt, 0)
# update reRate given the self-generated outcome
# in formal R-learning, we should minus Q here. However, they should cancel out since E(Q) = 0
# also, we use requiredHt + iti here
delta  = (trialEarnings - (spentHt + iti) * reRate) /  (spentHt + iti)
reRate = reRate + (1 - (1 -beta) ^ (spentHt + iti)) * delta
#update blockTime and trialIndex
blockTime = blockTime + spentHt + iti
# save variables
if(blockTime <= blockSec){
tIdxInChunk_[tIdx] = ifelse(tIdx %% chunkSize == 0, chunkSize, tIdx %% chunkSize)
cIdxInBlock_[tIdx] = ceiling(tIdx / chunkSize)
condition_[tIdx] = condition
scheduledHt_[tIdx] = scheduledHt
spentHt_[tIdx] = spentHt
blockTime_[tIdx] = blockTime
trialEarnings_[tIdx] = trialEarnings
reRate_[tIdx] = reRate
delta_[tIdx] = delta
}
# update trial index
tIdx = tIdx + 1
}
# truncate and save
tempt = data.frame(
"condition" = condition_,
'tIdxInChunk' = tIdxInChunk_,
'cIdxInBlock' = cIdxInBlock_,
'scheduledHt' = scheduledHt_,
'spentHt' = spentHt_,
'blockTime' = blockTime_,
'trialEarnings' = trialEarnings_,
'reRate' = reRate_,
'delta' = delta_
)
nTrial = sum(!is.na(condition_), na.rm = T)
tempt = tempt[1 : nTrial,]
if(condition == "rich"){
richOutputs = tempt
}else{
poorOutputs = tempt
}
}
# combine data from the two conditions
junk = rbind(richOutputs, poorOutputs)
junk$ckIdxInTask = junk$cIdxInBlock
junk$ckIdxInTask[junk$condition == conditions[2]] =  junk$ckIdxInTask[junk$condition == conditions[2]] +
tail(junk$ckIdxInTask[junk$condition == conditions[1]], 1)
# count chunks and trials
nChunk = length(unique(junk$ckIdxInTask))
nTrial = nrow(junk)
# calculate how responses to prob stims change
acceptMatrix = matrix(NA, nUnqHt, nChunk)
for(i in 1 : nUnqHt){
for(j in 1 : nChunk){
if(sum(junk$scheduledHt == unqHts[i] & junk$ckIdxInTask == j) != 0){
acceptMatrix[i, j] = mean(junk$trialEarnings[junk$scheduledHt == unqHts[i] & junk$ckIdxInTask == j] == rwd)
}else{
acceptMatrix[i, j] = NA
}
}
}
acceptMatrix
unqHts
i = 2
sum(junk$scheduledHt == unqHts[i] & junk$ckIdxInTask == j) != 0
junk$scheduledHt
source("social_nonSocial.R")
library("dplyr")
library("tidyr")
# load expPara
load("expParas.RData")
# create the ht sequences in two conditions
htSeq_ = lapply(1 : nCondition, function(i) {
condition = conditions[i]
tempt = as.vector(replicate(nChunkMax, sample(hts_[[condition]], chunkSize)))
tempt[1 : nTrialMax]
})
source("social_nonSocial.R")
library("dplyr")
library("tidyr")
# load expPara
load("expParas.RData")
# create the ht sequences in two conditions
htSeq_ = lapply(1 : nCondition, function(i) {
condition = conditions[i]
tempt = as.vector(replicate(nChunkMax, sample(hts_[[condition]], chunkSize)))
tempt[1 : nTrialMax]
})
# shuffle all possive rewards to generate the reward sequence
# call the function
social_nonSocial(htSeq_)
